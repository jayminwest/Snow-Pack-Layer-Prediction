{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, os, utils, urllib\n",
    "from datetime import datetime, timedelta\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "all_zones_df = utils.clean_raw_webscraper_data('output_data/All_Zones_2021-22_Season_reports_data.csv')\n",
    "all_zones_df = utils.add_weather_to_reports(all_zones_df)\n",
    "all_zones_df.to_csv('output_data/All_Zones_2021-22_Season_weather_and_reports_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zones_df = pd.read_csv('output_data/all_zones_all_data.csv')\n",
    "\n",
    "data = all_zones_df.drop(columns=['bottom_line_text', 'problem_type_text', 'forecast_discussion_text'])\n",
    "\n",
    "data['combined_text'] = data['combined_text'].astype(str)\n",
    "data['combined_text'] = data['combined_text'].apply(lambda x: word_tokenize(x.lower()))\n",
    "data.rename(columns={'combined_text': 'tokens'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('since', 0.8743607997894287),\n",
       " ('in', 0.8464764952659607),\n",
       " ('total', 0.8372876048088074),\n",
       " ('prior', 0.8291876912117004),\n",
       " ('backed', 0.8236643075942993),\n",
       " ('associated', 0.8191325068473816),\n",
       " ('received', 0.8190154433250427),\n",
       " ('blew', 0.8183265328407288),\n",
       " ('brought', 0.8003273010253906),\n",
       " ('wrapped', 0.7978445887565613)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the word to vec model:\n",
    "model = Word2Vec(sentences=data['tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.save('models/first_word2vec.model')\n",
    "\n",
    "# Create word embeddings lookup dictionary\n",
    "word_embeddings = {}\n",
    "\n",
    "for word in model.wv.index_to_key:\n",
    "    word_embeddings[word] = model.wv[word]\n",
    "\n",
    "word = 'storm'\n",
    "model.wv.most_similar(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 00:08:34.059120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-09 00:08:34.064534: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-09 00:08:34.068463: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 00:08:34.831501: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-09 00:08:34.835589: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-09 00:08:34.840904: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-09 00:08:36.606662: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-09 00:08:36.611108: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-09 00:08:36.614329: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 11s 200ms/step - loss: 2.3231\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 7s 196ms/step - loss: 0.8536\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 7s 199ms/step - loss: 0.8528\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 7s 196ms/step - loss: 0.8562\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 7s 197ms/step - loss: 0.8583\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 7s 197ms/step - loss: 0.8585\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 7s 200ms/step - loss: 0.8586\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 7s 198ms/step - loss: 0.8548\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 7s 197ms/step - loss: 0.8586\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 8s 226ms/step - loss: 0.8642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 00:09:53.295316: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-09 00:09:53.299922: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-09 00:09:53.303582: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 855ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m predictions \u001b[39m=\u001b[39m []\n\u001b[1;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m7\u001b[39m):\n\u001b[0;32m---> 67\u001b[0m     next_sequence \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate([last_sequence[\u001b[39m1\u001b[39;49m:], np\u001b[39m.\u001b[39;49mzeros(\u001b[39m1\u001b[39;49m)])  \u001b[39m# Shift the sequence by one position\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     next_sequence \u001b[39m=\u001b[39m next_sequence\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# Reshape to match the input shape\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(next_sequence)[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]  \u001b[39m# Make the prediction\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import Word2Vec\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "\n",
    "# Load the dataframe\n",
    "# df = pd.read_csv('your_dataframe.csv')\n",
    "df = data\n",
    "\n",
    "# Select the features you want to use for training\n",
    "features = ['tavg', 'tmin', 'tmax', 'prcp', 'wdir', 'pres', 'tsun']\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = MinMaxScaler()\n",
    "df[features] = scaler.fit_transform(df[features])  # Normalize the numerical features\n",
    "\n",
    "# Convert text tokens to numerical sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['tokens'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['tokens'])\n",
    "max_seq_length = max(len(seq) for seq in sequences)\n",
    "sequences = pad_sequences(sequences, maxlen=max_seq_length)\n",
    "\n",
    "tokenized_text = [str(tokens).split() for tokens in df['tokens']]\n",
    "# Train Word2Vec embeddings\n",
    "model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('models/first_word2vec.model')\n",
    "\n",
    "# Load pre-trained word embeddings (Word2Vec or GloVe)\n",
    "word_embeddings = Word2Vec.load('models/first_word2vec.model').wv\n",
    "\n",
    "# Create an embedding matrix\n",
    "embedding_dim = word_embeddings.vector_size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in word_embeddings.key_to_index:\n",
    "        embedding_matrix[i] = word_embeddings[word]\n",
    "\n",
    "# Prepare the input and output data\n",
    "X = sequences\n",
    "y = df['overall_risk'].values\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_seq_length, trainable=False))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "# Predict for the next 7 days\n",
    "last_sequence = sequences[-1]  # Get the last sequence from the input data\n",
    "\n",
    "predictions = []\n",
    "for _ in range(7):\n",
    "    next_sequence = np.concatenate([last_sequence[1:], np.zeros(1)])  # Shift the sequence by one position\n",
    "    next_sequence = next_sequence.reshape(1, -1)  # Reshape to match the input shape\n",
    "    prediction = model.predict(next_sequence)[0][0]  # Make the prediction\n",
    "    predictions.append(prediction)\n",
    "\n",
    "    # Update the last sequence with the predicted value\n",
    "    last_sequence[-1] = prediction\n",
    "    last_sequence = last_sequence.reshape(1, -1)\n",
    "\n",
    "# Print the predictions for the next 7 days\n",
    "print(\"Predictions for the next 7 days:\")\n",
    "for i, prediction in enumerate(predictions, 1):\n",
    "    print(f\"Day {i}: {prediction}\")\n",
    "\n",
    "# Chart the predictions\n",
    "days = range(1, 8)\n",
    "risk_levels = predictions\n",
    "\n",
    "p = figure(title=\"Risk Level Predictions for Next 7 Days\", x_axis_label=\"Day\", y_axis_label=\"Risk\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to sequences of word embeddings\n",
    "max_sequence_length = max(data['tokens'].apply(len))\n",
    "embedding_dimension = 100\n",
    "\n",
    "def convert_text_to_embeddings(text):\n",
    "    embeddings = []\n",
    "    \n",
    "    for word in text:\n",
    "        if word in word_embeddings:\n",
    "            embeddings.append(word_embeddings[word])\n",
    "        else:\n",
    "            embeddings.append([0.0] * embedding_dimension)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "sequences = data['tokens'].apply(convert_text_to_embeddings)\n",
    "\n",
    "# Update the padding step\n",
    "padded_sequences = pad_sequences(sequences.apply(lambda x: [elem[:embedding_dimension] for elem in x]),\n",
    "                                maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# padded_sequences = padded_sequences.reshape(padded_sequences.shape[0], padded_sequences.shape[1], embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1180, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = data.drop(columns=['tokens'])\n",
    "shape = data.shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model\n",
    "num_lstm_units = 64\n",
    "num_classes = 5\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Embedding(input_dim=len(word_embeddings), output_dim=embedding_dimension,\n",
    "#                     input_length=max_sequence_length, trainable=False))\n",
    "model.add(LSTM(units=num_lstm_units))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>zone</th>\n",
       "      <th>overall_risk</th>\n",
       "      <th>above_treeline_risk</th>\n",
       "      <th>near_treeline_risk</th>\n",
       "      <th>below_treeline_risk</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>pres</th>\n",
       "      <th>tsun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>east slopes north</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.3</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>west slopes central</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.4</td>\n",
       "      <td>1026.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>west slopes south</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.4</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>east slopes central</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.1</td>\n",
       "      <td>1025.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>snoqualmie pass</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.1</td>\n",
       "      <td>1025.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                 zone  overall_risk  above_treeline_risk   \n",
       "0  2022-04-23    east slopes north           3.0                  3.0  \\\n",
       "1  2022-04-23  west slopes central           3.0                  3.0   \n",
       "2  2022-04-23    west slopes south           3.0                  3.0   \n",
       "3  2022-04-23  east slopes central           2.0                  2.0   \n",
       "4  2022-04-23      snoqualmie pass           3.0                  3.0   \n",
       "\n",
       "   near_treeline_risk  below_treeline_risk  tavg  tmin  tmax  prcp   wdir   \n",
       "0                 3.0                  2.0   7.6  -0.9  15.9   0.0  225.3  \\\n",
       "1                 3.0                  2.0   9.9   4.6  15.4   0.0  242.4   \n",
       "2                 3.0                  2.0   9.9   4.4  16.3   0.0  279.4   \n",
       "3                 2.0                  2.0  10.6   5.3  16.3   0.0  282.1   \n",
       "4                 3.0                  2.0  10.2   4.8  16.3   0.0  274.1   \n",
       "\n",
       "     pres  tsun  \n",
       "0  1024.0   0.0  \n",
       "1  1026.2   0.0  \n",
       "2  1026.0   0.0  \n",
       "3  1025.4   0.0  \n",
       "4  1025.8   0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/.venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/.venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/.venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/.venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/.venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/.venv/lib/python3.10/site-packages/keras/backend.py\", line 2464, in dot\n        out = tf.matmul(x, y)\n\n    TypeError: Exception encountered when calling layer 'lstm_3' (type LSTM).\n    \n    Input 'b' of 'MatMul' Op has type float32 that does not match type int32 of argument 'a'.\n    \n    Call arguments received by layer 'lstm_3' (type LSTM):\n      • inputs=tf.Tensor(shape=(None, 435, 100), dtype=int32)\n      • mask=None\n      • training=True\n      • initial_state=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m X_train \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint32)\n\u001b[1;32m     10\u001b[0m X_val \u001b[39m=\u001b[39m X_val\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint32)\n\u001b[0;32m---> 12\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val), epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/Spring 2023/CPSC325/SnowPackPrediction/.venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filers8997uy.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/.venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/.venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/.venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/.venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/.venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/.venv/lib/python3.10/site-packages/keras/backend.py\", line 2464, in dot\n        out = tf.matmul(x, y)\n\n    TypeError: Exception encountered when calling layer 'lstm_3' (type LSTM).\n    \n    Input 'b' of 'MatMul' Op has type float32 that does not match type int32 of argument 'a'.\n    \n    Call arguments received by layer 'lstm_3' (type LSTM):\n      • inputs=tf.Tensor(shape=(None, 435, 100), dtype=int32)\n      • mask=None\n      • training=True\n      • initial_state=None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split data into training and validation sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "\n",
    "X_train = padded_sequences[:train_size]\n",
    "y_train = data['overall_risk'].values[:train_size]\n",
    "X_val = padded_sequences[train_size:]\n",
    "y_val = data['overall_risk'].values[train_size:]\n",
    "\n",
    "X_train = X_train.astype(np.int32)\n",
    "X_val = X_val.astype(np.int32)\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the LSTM model\n",
    "\n",
    "\n",
    "# Example prediction\n",
    "new_text = ['Slabs of snow are sitting on top of a weak layer of sugary snow.']\n",
    "new_tokens = word_tokenize(new_text[0].lower())\n",
    "new_sequence = convert_text_to_embeddings(new_tokens)\n",
    "new_padded_sequence = pad_sequences([new_sequence], maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# prediction = model.predict(new_padded_sequence)\n",
    "# predicted_label = prediction.argmax(axis=-1)[0]\n",
    "# print(f\"Predicted label: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
