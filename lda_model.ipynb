{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Processing of Avalanche Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>zone</th>\n",
       "      <th>overall_risk</th>\n",
       "      <th>above_treeline_risk</th>\n",
       "      <th>near_treeline_risk</th>\n",
       "      <th>below_treeline_risk</th>\n",
       "      <th>bottom_line_text</th>\n",
       "      <th>problem_type_text</th>\n",
       "      <th>forecast_discussion_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Mt Hood</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>As new snow starts piling up, think about avoi...</td>\n",
       "      <td>An approaching storm will bring moderate preci...</td>\n",
       "      <td>This incoming system is expected to hit the Mt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>East Slopes South</td>\n",
       "      <td>LOW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Generally safe avalanche conditions exist.  Ho...</td>\n",
       "      <td>A skiff of new snow and a good dose of strong ...</td>\n",
       "      <td>The main story for Sunday will likely be the g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>East Slopes North</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A weak storm will bring light rain below treel...</td>\n",
       "      <td>Sunday's storm will bring more wind than snow,...</td>\n",
       "      <td>Access in the East North zone is difficult and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>West Slopes South</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>You may see the wind building new slabs throug...</td>\n",
       "      <td>You may not find any wind slabs to start the d...</td>\n",
       "      <td>Right off the bat in the morning, you may not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Snoqualmie Pass</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A couple of inches of new snow in the afternoo...</td>\n",
       "      <td>You may see a wind slab problem start to devel...</td>\n",
       "      <td>First thing Sunday morning, you may find gener...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date               zone overall_risk  above_treeline_risk  \\\n",
       "0  2023-04-15            Mt Hood     MODERATE                  2.0   \n",
       "1  2023-04-15  East Slopes South          LOW                  1.0   \n",
       "2  2023-04-15  East Slopes North     MODERATE                  2.0   \n",
       "3  2023-04-15  West Slopes South     MODERATE                  2.0   \n",
       "4  2023-04-15    Snoqualmie Pass     MODERATE                  2.0   \n",
       "\n",
       "   near_treeline_risk  below_treeline_risk  \\\n",
       "0                 2.0                  1.0   \n",
       "1                 1.0                  1.0   \n",
       "2                 1.0                  1.0   \n",
       "3                 2.0                  1.0   \n",
       "4                 1.0                  1.0   \n",
       "\n",
       "                                    bottom_line_text  \\\n",
       "0  As new snow starts piling up, think about avoi...   \n",
       "1  Generally safe avalanche conditions exist.  Ho...   \n",
       "2  A weak storm will bring light rain below treel...   \n",
       "3  You may see the wind building new slabs throug...   \n",
       "4  A couple of inches of new snow in the afternoo...   \n",
       "\n",
       "                                   problem_type_text  \\\n",
       "0  An approaching storm will bring moderate preci...   \n",
       "1  A skiff of new snow and a good dose of strong ...   \n",
       "2  Sunday's storm will bring more wind than snow,...   \n",
       "3  You may not find any wind slabs to start the d...   \n",
       "4  You may see a wind slab problem start to devel...   \n",
       "\n",
       "                            forecast_discussion_text  \n",
       "0  This incoming system is expected to hit the Mt...  \n",
       "1  The main story for Sunday will likely be the g...  \n",
       "2  Access in the East North zone is difficult and...  \n",
       "3  Right off the bat in the morning, you may not ...  \n",
       "4  First thing Sunday morning, you may find gener...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('output_data/incomplete_All_Zones_Current_Season_reports_data.csv')\n",
    "all_data.columns = columns=['date', 'zone', 'overall_risk', 'above_treeline_risk', 'near_treeline_risk', 'below_treeline_risk', 'bottom_line_text', 'problem_type_text', 'forecast_discussion_text']\n",
    "all_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and using an LDA Model on the data:\n",
    "- Should compare the differences between teh tree columns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data for the LDA Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jaymin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jaymin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jaymin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "from gensim import corpora, models\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # adding days of the week to stop words\n",
    "    stop_words.update(['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday'])\n",
    "    # adding months to stop words\n",
    "    stop_words.update(['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august',\n",
    "                       'september', 'october', 'november', 'december'])\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    words = word_tokenize(text.lower())\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    words = simple_preprocess(str(words), deacc=True)\n",
    "    \n",
    "    return words\n",
    "\n",
    "def prepare_text_column(column):\n",
    "    \"\"\"\n",
    "    Prepares a text column for LDA analysis.\n",
    "    \"\"\"\n",
    "    column = [str(item) for item in column]\n",
    "    processed = [preprocess(doc) for doc in column]\n",
    "\n",
    "    # Create a dictionary of terms and their frequency\n",
    "    dictionary = corpora.Dictionary(processed)\n",
    "\n",
    "    # Create a document-term matrix\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in processed]\n",
    "\n",
    "    return doc_term_matrix, dictionary\n",
    "\n",
    "# Load the dataset\n",
    "bl_matrix, bl_dict = prepare_text_column(all_data['bottom_line_text'].to_list())\n",
    "pt_matrix, pt_dict = prepare_text_column(all_data['problem_type_text'].to_list())\n",
    "fd_matrix, fd_dict = prepare_text_column(all_data['forecast_discussion_text'].to_list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the LDA Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LDA models\n",
    "bl_model = LdaModel(bl_matrix, num_topics=5, id2word=bl_dict, passes=10)\n",
    "pd_model = LdaModel(pt_matrix, num_topics=5, id2word=pt_dict, passes=10)\n",
    "fd_model = LdaModel(fd_matrix, num_topics=10, id2word=fd_dict, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.061*\"wind\" + 0.048*\"slab\" + 0.031*\"snow\" + 0.014*\"slope\" + 0.012*\"new\" + 0.011*\"avalanche\" + 0.011*\"could\" + 0.010*\"terrain\" + 0.009*\"loaded\" + 0.008*\"find\"\n",
      "Topic: 1 \n",
      "Words: 0.049*\"wind\" + 0.044*\"snow\" + 0.028*\"slab\" + 0.028*\"slope\" + 0.018*\"avalanche\" + 0.018*\"terrain\" + 0.013*\"steep\" + 0.012*\"surface\" + 0.011*\"trigger\" + 0.011*\"could\"\n",
      "Topic: 2 \n",
      "Words: 0.039*\"snow\" + 0.039*\"avalanche\" + 0.036*\"wet\" + 0.023*\"slope\" + 0.017*\"could\" + 0.016*\"loose\" + 0.013*\"slab\" + 0.012*\"slide\" + 0.011*\"surface\" + 0.011*\"steep\"\n",
      "Topic: 3 \n",
      "Words: 0.023*\"avalanche\" + 0.021*\"day\" + 0.020*\"slope\" + 0.020*\"storm\" + 0.014*\"snow\" + 0.013*\"large\" + 0.013*\"slab\" + 0.013*\"could\" + 0.012*\"wind\" + 0.010*\"steep\"\n",
      "Topic: 4 \n",
      "Words: 0.039*\"snow\" + 0.034*\"avalanche\" + 0.022*\"wind\" + 0.021*\"slab\" + 0.021*\"could\" + 0.016*\"slope\" + 0.014*\"steep\" + 0.011*\"terrain\" + 0.010*\"wet\" + 0.010*\"new\"\n"
     ]
    }
   ],
   "source": [
    "# Print the topics and their corresponding keywords\n",
    "for idx, topic in pd_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
