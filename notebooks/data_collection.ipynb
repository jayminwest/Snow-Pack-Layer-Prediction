{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection of Data for Snowpack Layer Prediction and Analysis\n",
    "### Jaymin West\n",
    "\n",
    "### Spring, 2023\n",
    "\n",
    "#### The purpose of this project is to create a model that predicts the current snow conditions in areas based on the weather that that area has seen and predict the avalanche risk of that area based on this. By “snow conditions” I mean the layers that exist within the snow pack such as hard, frozen layers or soft, dry layers. Understanding the layers within a snowpack is essential to predicting avalanche risk of an area. Currently, avalanche risk assessment and snow pack analysis are done entirely by professional avalanche forecasters who go into the field, dig snow pits, analayze the snowpack, and create a risk assessment based on this information. The goal with this project is not to replace these highly educated individuals but instead to attempt to create a tool that may help those interested in snow packs better understand the conditions they may face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, os, utils, urllib\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from meteostat import Stations, Daily, Point, Hourly\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "all_zones_df = utils.clean_raw_webscraper_data('output_data/All_Zones_2021-22_Season_reports_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/sql/schema.py:478\u001b[0m, in \u001b[0;36mTable._new\u001b[0;34m(cls, *args, **kw)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m     table\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(name, metadata, \u001b[39m*\u001b[39;49margs, _no_init\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    479\u001b[0m     table\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_parent_attach(table, metadata)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/sql/schema.py:810\u001b[0m, in \u001b[0;36mTable.__init__\u001b[0;34m(self, name, metadata, schema, quote, quote_schema, autoload_with, autoload_replace, keep_existing, extend_existing, resolve_fks, include_columns, implicit_returning, comment, info, listeners, prefixes, _extend_on, _no_init, *args, **kw)\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 810\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(quoted_name(name, quote))\n\u001b[1;32m    811\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39m=\u001b[39m metadata\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:5023\u001b[0m, in \u001b[0;36mquoted_name.__new__\u001b[0;34m(cls, value, quote)\u001b[0m\n\u001b[1;32m   5022\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, value: \u001b[39mstr\u001b[39m, quote: Optional[\u001b[39mbool\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m quoted_name:\n\u001b[0;32m-> 5023\u001b[0m     \u001b[39massert\u001b[39;00m (\n\u001b[1;32m   5024\u001b[0m         value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   5025\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39muse quoted_name.construct() for None passthrough\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   5026\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mcls\u001b[39m) \u001b[39mand\u001b[39;00m (quote \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m value\u001b[39m.\u001b[39mquote \u001b[39m==\u001b[39m quote):\n",
      "\u001b[0;31mAssertionError\u001b[0m: use quoted_name.construct() for None passthrough",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/data_collection.ipynb Cell 4\u001b[0m in \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m all_zones_df \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39madd_weather_to_reports(all_zones_df)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m all_zones_df\u001b[39m.\u001b[39mhead()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m utils\u001b[39m.\u001b[39mdataframe_to_postgres(all_zones_df)\n",
      "File \u001b[0;32m~/Desktop/Spring 2023/CPSC325/SnowPackPrediction/utils.py:198\u001b[0m, in \u001b[0;36mdataframe_to_postgres\u001b[0;34m(df, table_name)\u001b[0m\n\u001b[1;32m    195\u001b[0m engine \u001b[39m=\u001b[39m create_engine(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpostgresql://\u001b[39m\u001b[39m{\u001b[39;00mkeys\u001b[39m.\u001b[39mPOSTGRESQL_ADDON_USER\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mkeys\u001b[39m.\u001b[39mPOSTGRESQL_ADDON_PASSWORD\u001b[39m}\u001b[39;00m\u001b[39m@\u001b[39m\u001b[39m{\u001b[39;00mkeys\u001b[39m.\u001b[39mPOSTGRESQL_ADDON_HOST\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mkeys\u001b[39m.\u001b[39mPOSTGRESQL_ADDON_PORT\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mkeys\u001b[39m.\u001b[39mPOSTGRESQL_DB\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    197\u001b[0m \u001b[39m# Insert DataFrame into PostgreSQL table\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m df\u001b[39m.\u001b[39;49mto_sql(table_name, engine, if_exists\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mreplace\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    200\u001b[0m \u001b[39m# Close the database connection\u001b[39;00m\n\u001b[1;32m    201\u001b[0m engine\u001b[39m.\u001b[39mdispose()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:2986\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2829\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2830\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2831\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2982\u001b[0m \u001b[39m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   2983\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa:E501\u001b[39;00m\n\u001b[1;32m   2984\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m sql\n\u001b[0;32m-> 2986\u001b[0m \u001b[39mreturn\u001b[39;00m sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[1;32m   2987\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2988\u001b[0m     name,\n\u001b[1;32m   2989\u001b[0m     con,\n\u001b[1;32m   2990\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m   2991\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m   2992\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   2993\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   2994\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   2995\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   2996\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   2997\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:696\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(frame, DataFrame):\n\u001b[1;32m    692\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    693\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument should be either a Series or a DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[0;32m--> 696\u001b[0m \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[1;32m    697\u001b[0m     frame,\n\u001b[1;32m    698\u001b[0m     name,\n\u001b[1;32m    699\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m    700\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    701\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m    702\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m    703\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    704\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    705\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    706\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    707\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mengine_kwargs,\n\u001b[1;32m    708\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:1729\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1680\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1725\u001b[0m \u001b[39m    Any additional kwargs are passed to the engine.\u001b[39;00m\n\u001b[1;32m   1726\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1727\u001b[0m sql_engine \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m-> 1729\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprep_table(\n\u001b[1;32m   1730\u001b[0m     frame\u001b[39m=\u001b[39;49mframe,\n\u001b[1;32m   1731\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1732\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m   1733\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   1734\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   1735\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m   1736\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1737\u001b[0m )\n\u001b[1;32m   1739\u001b[0m total_inserted \u001b[39m=\u001b[39m sql_engine\u001b[39m.\u001b[39minsert_records(\n\u001b[1;32m   1740\u001b[0m     table\u001b[39m=\u001b[39mtable,\n\u001b[1;32m   1741\u001b[0m     con\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnectable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1748\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mengine_kwargs,\n\u001b[1;32m   1749\u001b[0m )\n\u001b[1;32m   1751\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_case_sensitive(name\u001b[39m=\u001b[39mname, schema\u001b[39m=\u001b[39mschema)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:1622\u001b[0m, in \u001b[0;36mSQLDatabase.prep_table\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, dtype)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(to_instance(my_type), TypeEngine):\n\u001b[1;32m   1620\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe type of \u001b[39m\u001b[39m{\u001b[39;00mcol\u001b[39m}\u001b[39;00m\u001b[39m is not a SQLAlchemy type\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1622\u001b[0m table \u001b[39m=\u001b[39m SQLTable(\n\u001b[1;32m   1623\u001b[0m     name,\n\u001b[1;32m   1624\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1625\u001b[0m     frame\u001b[39m=\u001b[39;49mframe,\n\u001b[1;32m   1626\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   1627\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m   1628\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   1629\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m   1630\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1631\u001b[0m )\n\u001b[1;32m   1632\u001b[0m table\u001b[39m.\u001b[39mcreate()\n\u001b[1;32m   1633\u001b[0m \u001b[39mreturn\u001b[39;00m table\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:806\u001b[0m, in \u001b[0;36mSQLTable.__init__\u001b[0;34m(self, name, pandas_sql_engine, frame, index, if_exists, prefix, index_label, schema, keys, dtype)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m dtype\n\u001b[1;32m    804\u001b[0m \u001b[39mif\u001b[39;00m frame \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    805\u001b[0m     \u001b[39m# We want to initialize based on a dataframe\u001b[39;00m\n\u001b[0;32m--> 806\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_table_setup()\n\u001b[1;32m    807\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    808\u001b[0m     \u001b[39m# no data provided, read-only mode\u001b[39;00m\n\u001b[1;32m    809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpd_sql\u001b[39m.\u001b[39mget_table(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:1103\u001b[0m, in \u001b[0;36mSQLTable._create_table_setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[39m# At this point, attach to new metadata, only attach to self.meta\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m \u001b[39m# once table is created.\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m meta \u001b[39m=\u001b[39m MetaData()\n\u001b[0;32m-> 1103\u001b[0m \u001b[39mreturn\u001b[39;00m Table(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, meta, \u001b[39m*\u001b[39;49mcolumns, schema\u001b[39m=\u001b[39;49mschema)\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kw)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/util/deprecations.py:277\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    271\u001b[0m         _warn_with_version(\n\u001b[1;32m    272\u001b[0m             messages[m],\n\u001b[1;32m    273\u001b[0m             versions[m],\n\u001b[1;32m    274\u001b[0m             version_warnings[m],\n\u001b[1;32m    275\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/sql/schema.py:428\u001b[0m, in \u001b[0;36mTable.__new__\u001b[0;34m(cls, *args, **kw)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[39m@util\u001b[39m\u001b[39m.\u001b[39mdeprecated_params(\n\u001b[1;32m    422\u001b[0m     mustexist\u001b[39m=\u001b[39m(\n\u001b[1;32m    423\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m1.4\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    426\u001b[0m )\n\u001b[1;32m    427\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 428\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_new(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/sql/schema.py:482\u001b[0m, in \u001b[0;36mTable._new\u001b[0;34m(cls, *args, **kw)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[39mreturn\u001b[39;00m table\n\u001b[1;32m    481\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m--> 482\u001b[0m     \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39msafe_reraise():\n\u001b[1;32m    483\u001b[0m         metadata\u001b[39m.\u001b[39m_remove_table(name, schema)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:151\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# remove potential circular references\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39massert\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(traceback)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/sql/schema.py:483\u001b[0m, in \u001b[0;36mTable._new\u001b[0;34m(cls, *args, **kw)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    482\u001b[0m     \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39msafe_reraise():\n\u001b[0;32m--> 483\u001b[0m         metadata\u001b[39m.\u001b[39;49m_remove_table(name, schema)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/sql/schema.py:5288\u001b[0m, in \u001b[0;36mMetaData._remove_table\u001b[0;34m(self, name, schema)\u001b[0m\n\u001b[1;32m   5286\u001b[0m removed \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m\u001b[39m.\u001b[39mpop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtables, key, \u001b[39mNone\u001b[39;00m)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   5287\u001b[0m \u001b[39mif\u001b[39;00m removed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 5288\u001b[0m     \u001b[39mfor\u001b[39;00m fk \u001b[39min\u001b[39;00m removed\u001b[39m.\u001b[39;49mforeign_keys:\n\u001b[1;32m   5289\u001b[0m         fk\u001b[39m.\u001b[39m_remove_from_metadata(\u001b[39mself\u001b[39m)\n\u001b[1;32m   5290\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_schemas:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:1138\u001b[0m, in \u001b[0;36m_memoized_property.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m-> 1138\u001b[0m obj\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m] \u001b[39m=\u001b[39m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfget(obj)\n\u001b[1;32m   1139\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/sql/selectable.py:922\u001b[0m, in \u001b[0;36mFromClause.foreign_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_collections()\n\u001b[1;32m    921\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_populate_column_collection()\n\u001b[0;32m--> 922\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforeign_keys\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:1138\u001b[0m, in \u001b[0;36m_memoized_property.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m-> 1138\u001b[0m obj\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m] \u001b[39m=\u001b[39m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfget(obj)\n\u001b[1;32m   1139\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/sql/selectable.py:922\u001b[0m, in \u001b[0;36mFromClause.foreign_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_collections()\n\u001b[1;32m    921\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_populate_column_collection()\n\u001b[0;32m--> 922\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforeign_keys\n",
      "    \u001b[0;31m[... skipping similar frames: _memoized_property.__get__ at line 1138 (1477 times), FromClause.foreign_keys at line 922 (1476 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/sql/selectable.py:922\u001b[0m, in \u001b[0;36mFromClause.foreign_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_collections()\n\u001b[1;32m    921\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_populate_column_collection()\n\u001b[0;32m--> 922\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforeign_keys\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:1138\u001b[0m, in \u001b[0;36m_memoized_property.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m-> 1138\u001b[0m obj\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m] \u001b[39m=\u001b[39m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfget(obj)\n\u001b[1;32m   1139\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "all_zones_df = all_zones_df.head(1)\n",
    "all_zones_df = utils.add_weather_to_reports(all_zones_df)\n",
    "all_zones_df.head()\n",
    "utils.dataframe_to_postgres(all_zones_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an LSTM to predict the current avalanche danger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/snap/core20/current/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /lib/x86_64-linux-gnu/libproxy.so.1)\n",
      "Failed to load module: /home/jaymin/snap/code/common/.cache/gio-modules/libgiolibproxy.so\n",
      "libva error: vaGetDriverNameByIndex() failed with unknown libva error, driver_name = (null)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening in existing browser session.\n"
     ]
    }
   ],
   "source": [
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "p = figure(title=\"Avalanche Risk 22-23\", x_axis_label='Date', y_axis_label='Value')\n",
    "\n",
    "p.line(x='time', y='temp', legend_label=\"Temperature\", color='red', source=weather_and_risk_df)\n",
    "# p.line(x='time', y='dwpt', legend_label=\"Dew Point\", source=weather_and_risk_df)\n",
    "# p.line(x='time', y='rhum', legend_label=\"Relative Humidity\", source=weather_and_risk_df)\n",
    "# p.line(x='time', y='prcp', legend_label=\"Precipitation\", source=weather_and_risk_df)\n",
    "# p.line(x='time', y='wdir', legend_label=\"Wind Direction\", source=weather_and_risk_df)\n",
    "p.line(x='time', y='wspd', legend_label=\"Wind Speed\", source=weather_and_risk_df)\n",
    "# p.line(x='time', y='pres', legend_label=\"Pressure\", source=weather_and_risk_df)\n",
    "# p.line(x='time', y='coco', legend_label=\"Cloud Cover\", source=weather_and_risk_df)\n",
    "\n",
    "hover = HoverTool(tooltips=[(\"Avalanche Risk\", \"@risk\")], mode='vline')\n",
    "p.add_tools(hover)\n",
    "\n",
    "output_file(\"output_data/avalanche_risk_22-23.html\")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "8/8 [==============================] - 5s 11ms/step - loss: 2.1643\n",
      "Epoch 2/16\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.9405\n",
      "Epoch 3/16\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.7272\n",
      "Epoch 4/16\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.4953\n",
      "Epoch 5/16\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.2299\n",
      "Epoch 6/16\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9206\n",
      "Epoch 7/16\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6316\n",
      "Epoch 8/16\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6196\n",
      "Epoch 9/16\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6109\n",
      "Epoch 10/16\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5933\n",
      "Epoch 11/16\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6004\n",
      "Epoch 12/16\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6023\n",
      "Epoch 13/16\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5972\n",
      "Epoch 14/16\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5993\n",
      "Epoch 15/16\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5965\n",
      "Epoch 16/16\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5937\n",
      "Test MSE: 0.491\n"
     ]
    }
   ],
   "source": [
    "weather_and_risk_df['time'] = pd.to_datetime(weather_and_risk_df['time'])\n",
    "weather_and_risk_df['time'] = weather_and_risk_df['time'].apply(lambda x: x.timestamp())\n",
    "\n",
    "X = weather_and_risk_df.iloc[:, :-1].values\n",
    "y = weather_and_risk_df.iloc[:, -1].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "n_samples, n_time_steps = X.shape\n",
    "n_features = 1\n",
    "X = X.reshape((n_samples, n_time_steps, n_features))\n",
    "\n",
    "train_sie = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_sie], X[train_sie:]\n",
    "y_train, y_test = y[:train_sie], y[train_sie:]\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_time_steps, n_features)))\n",
    "model.add(Bidirectional(LSTM(25, activation='relu'), input_shape=(n_time_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=16, batch_size=16, verbose=1)\n",
    "\n",
    "mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test MSE: %.3f' % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temp</th>\n",
       "      <th>dwpt</th>\n",
       "      <th>rhum</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "      <th>coco</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>92.9</td>\n",
       "      <td>78.6</td>\n",
       "      <td>319.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>84.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1037.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>73.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1033.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-8.7</td>\n",
       "      <td>74.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>91.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>281.6</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1022.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>83.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>322.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1015.1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2023-04-13</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>78.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1015.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>75.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1013.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>2.2</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1018.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>78.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>90.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1015.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time  temp  dwpt  rhum  prcp   wdir  wspd    pres  coco  risk\n",
       "0    2022-11-04   2.6   1.6  92.9  78.6  319.2   6.9  1008.0  16.0    -1\n",
       "1    2022-11-16  -4.7  -7.0  84.8   0.0   74.7   8.0  1037.2   5.0    -1\n",
       "2    2022-11-18  -6.5 -10.6  73.2   0.0   88.5   9.0  1033.9   1.0    -1\n",
       "3    2022-11-21  -4.8  -8.7  74.2   0.0   66.4   6.4  1026.0   3.0    -1\n",
       "4    2022-11-23   1.1  -0.2  91.6   4.2  281.6   8.4  1022.1  16.0    -1\n",
       "..          ...   ...   ...   ...   ...    ...   ...     ...   ...   ...\n",
       "145  2023-04-12  -2.0  -4.4  83.8   0.5  322.2   4.0  1015.1  21.0     1\n",
       "146  2023-04-13  -1.1  -4.6  78.3   0.0  277.7   7.5  1015.2   5.0     1\n",
       "147  2023-04-14   0.6  -3.7  75.4   0.0  279.2   5.6  1013.3   5.0     0\n",
       "148  2023-04-15   2.2  -3.0  69.0   0.3   51.9   4.4  1018.2   7.0     1\n",
       "149  2023-04-16   0.7  -2.7  78.7   3.9   90.4   7.2  1015.2  15.0    -1\n",
       "\n",
       "[150 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_and_risk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting data from the database:\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"dbname='snowpackprediction' user='jaymin' host='localhost' password='password'\")\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "weather_df = pd.DataFrame(cursor.execute(\"SELECT * FROM weather_data\"))\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Score:  0.4\n"
     ]
    }
   ],
   "source": [
    "X = weather_and_risk_df[['temp', 'dwpt', 'rhum', 'prcp', 'wdir', 'wspd', 'pres', 'coco']] # Features\n",
    "y = weather_and_risk_df['risk'] # Labels\n",
    "\n",
    "# Making a decision tree with Sklearn:\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X[:-10], y[:-10])\n",
    "# fig = plt.figure(figsize=(25,20))\n",
    "# fig = tree.plot_tree(clf)\n",
    "clf.predict(X[-10:])\n",
    "print(\"Decision Tree Score: \", clf.score(X[-10:], y[-10:]))\n",
    "# conf_matrix = confusion_matrix(clf.predict(X), y)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(3, 3))\n",
    "# ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "# for i in range(conf_matrix.shape[0]):\n",
    "#     for j in range(conf_matrix.shape[1]):\n",
    "#         ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "# plt.xlabel('Predictions', fontsize=18)\n",
    "# plt.ylabel('Actuals', fontsize=18)\n",
    "# plt.title('Confusion Matrix', fontsize=18)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/data_collection.ipynb Cell 13\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m report_text \u001b[39m=\u001b[39m row\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# report = row.find_all('a')[0]['href']\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X14sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m report \u001b[39m=\u001b[39m Select(browser\u001b[39m.\u001b[39mfind_element(By\u001b[39m.\u001b[39mLINK_TEXT(report_text)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(report)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m date \u001b[39m=\u001b[39m row\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39mtd\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "# Scraping the avalanche data from the NWAC website:\n",
    "\n",
    "# Xpath: //*[@id=\"afp-forecast-widget\"]/div/div/div[1]/div[2]/div[1]/table/tbody/tr[1]/td[1]/div/a\n",
    "\n",
    "# Using Selenium to get the avalanche forecast data:\n",
    "date_risks = []\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "url = 'https://nwac.us/avalanche-forecast/#/archive'\n",
    "browser.get(url)\n",
    "# Finding by XPATH:\n",
    "select_element = Select(browser.find_element(By.XPATH,'//*[@id=\"afp-forecast-widget\"]/div/div/div[1]/div[1]/div/div[1]/div[2]/div[2]/select'))\n",
    "# Selecting Snoqualmie Pass from dropdown menu:\n",
    "select_element.select_by_visible_text(\"Snoqualmie Pass\")\n",
    "\n",
    "response = browser.page_source\n",
    "\n",
    "soup = bs.BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "prediction_table = soup.find_all('tr', {'class': 'VueTables__row'})\n",
    "for row in prediction_table:\n",
    "    report_text = row.find_all('a')[0].text\n",
    "    # report = row.find_all('a')[0]['href']\n",
    "    report = Select(browser.find_element(By.LINK_TEXT(report_text)))\n",
    "    print(report)\n",
    "    date = row.find_all('td')[0].text\n",
    "\n",
    "    org_date = datetime.strptime(date, '%b %d, %Y')\n",
    "    new_date = datetime.strftime(org_date, '%Y-%m-%d')\n",
    "    new_date = datetime.strptime(new_date, '%Y-%m-%d')\n",
    "    date_risks.append([new_date, row.find_all('td')[5].text])\n",
    "\n",
    "# Going to the next page:\n",
    "select_element = browser.find_element(By.XPATH,'//*[@id=\"afp-forecast-widget\"]/div/div/div[1]/div[2]/div[2]/nav/ul/li[4]/a')\n",
    "select_element.click()\n",
    "\n",
    "response = browser.page_source\n",
    "\n",
    "soup = bs.BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "prediction_table = soup.find_all('tr', {'class': 'VueTables__row'})\n",
    "for row in prediction_table:\n",
    "    date = row.find_all('td')[0].text\n",
    "    org_date = datetime.strptime(date, '%b %d, %Y')\n",
    "    new_date = datetime.strftime(org_date, '%Y-%m-%d')\n",
    "    new_date = datetime.strptime(new_date, '%Y-%m-%d')\n",
    "    date_risks.append([new_date, row.find_all('td')[5].text])\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "date_risks = pd.DataFrame(date_risks, columns=['time', 'risk'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snowpilot Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExpatError",
     "evalue": "syntax error: line 1, column 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExpatError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/data_collection.ipynb Cell 13\u001b[0m in \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39m\"\u001b[39m\u001b[39minput_data/snowpilot_data\u001b[39m\u001b[39m\"\u001b[39m): \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minput_data/snowpilot_data/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m filename\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     timestamp \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(utils\u001b[39m.\u001b[39msnowpilot_xml_to_dict(filename)[\u001b[39m'\u001b[39m\u001b[39m@timestamp\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     timestamp \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m# Converting from milliseconds\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     date \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mfromtimestamp(timestamp)\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Spring 2023/CPSC325/SnowPackPrediction/utils.py:24\u001b[0m, in \u001b[0;36msnowpilot_xml_to_dict\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(fname, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m     22\u001b[0m     sp_xml \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread()\n\u001b[0;32m---> 24\u001b[0m sp_xml \u001b[39m=\u001b[39m xmltodict\u001b[39m.\u001b[39;49mparse(sp_xml)\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m sp_xml[\u001b[39m'\u001b[39m\u001b[39mPit_Observation\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xmltodict.py:378\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(xml_input, encoding, expat, process_namespaces, namespace_separator, disable_entities, process_comments, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m     parser\u001b[39m.\u001b[39mParse(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    377\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     parser\u001b[39m.\u001b[39;49mParse(xml_input, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    379\u001b[0m \u001b[39mreturn\u001b[39;00m handler\u001b[39m.\u001b[39mitem\n",
      "\u001b[0;31mExpatError\u001b[0m: syntax error: line 1, column 0"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "\n",
    "sp_data = []\n",
    "for filename in os.listdir(\"input_data/snowpilot_data\"): \n",
    "    filename = \"input_data/snowpilot_data/\" + filename\n",
    "    timestamp = int(utils.snowpilot_xml_to_dict(filename)['@timestamp'])\n",
    "    timestamp /= 1000 # Converting from milliseconds\n",
    "\n",
    "    date = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')\n",
    "\n",
    "    layers = utils.snowpilot_xml_to_dict(filename)['Layer']\n",
    "\n",
    "    layers_dict = {}\n",
    "\n",
    "    for layer in layers:\n",
    "        layers_dict[layer['@layerNumber']] = [layer['@startDepth'], layer['@endDepth'], layer['@hardness1']]\n",
    "\n",
    "    chart_df = pd.DataFrame.from_dict(layers_dict, orient='index', columns=['startDepth', 'endDepth', 'hardness1'])\n",
    "    sp_data.append((date, chart_df))\n",
    "sp_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas:\n",
    "\n",
    "- Really only need to predict the hardness of the snow layers. Graph can be made from everything else\n",
    "- Snow depth can be retrieved from the Snowpilot Data\n",
    "- Take basically all of the attributes possible from the weather data, use decision tree to find the most influential factors in determinding the layer hardness\n",
    "    - Will need to look at (some) historical data for the best results here\n",
    "- End results does not have to be the same format of the Snowpilot charts\n",
    "    - Could have the layers be color coded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
