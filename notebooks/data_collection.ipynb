{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection of Data for Snowpack Layer Prediction and Analysis\n",
    "### Jaymin West\n",
    "\n",
    "### Spring, 2023\n",
    "\n",
    "#### The purpose of this project is to create a model that predicts the current snow conditions in areas based on the weather that that area has seen and predict the avalanche risk of that area based on this. By “snow conditions” I mean the layers that exist within the snow pack such as hard, frozen layers or soft, dry layers. Understanding the layers within a snowpack is essential to predicting avalanche risk of an area. Currently, avalanche risk assessment and snow pack analysis are done entirely by professional avalanche forecasters who go into the field, dig snow pits, analayze the snowpack, and create a risk assessment based on this information. The goal with this project is not to replace these highly educated individuals but instead to attempt to create a tool that may help those interested in snow packs better understand the conditions they may face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, os, utils, urllib\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from meteostat import Stations, Daily, Point, Hourly\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottom_line_text\n",
      "problem_type_text\n",
      "forecast_discussion_text\n",
      "combined_text\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "all_zones_df = utils.clean_raw_webscraper_data('output_data/All_Zones_2021-22_Season_reports_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>zone</th>\n",
       "      <th>overall_risk</th>\n",
       "      <th>above_treeline_risk</th>\n",
       "      <th>near_treeline_risk</th>\n",
       "      <th>below_treeline_risk</th>\n",
       "      <th>bottom_line_text</th>\n",
       "      <th>problem_type_text</th>\n",
       "      <th>forecast_discussion_text</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>pres</th>\n",
       "      <th>tsun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>east slopes north</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>avalanche danger minimal morning quickly spike...</td>\n",
       "      <td>expect warmest temperature almost week enough ...</td>\n",
       "      <td>cornice fall snow blanket cornice rock face ne...</td>\n",
       "      <td>avalanche danger minimal morning quickly spike...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.3</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date               zone  overall_risk  above_treeline_risk  \\\n",
       "0 2022-04-23  east slopes north           3.0                  3.0   \n",
       "\n",
       "   near_treeline_risk  below_treeline_risk  \\\n",
       "0                 3.0                  2.0   \n",
       "\n",
       "                                    bottom_line_text  \\\n",
       "0  avalanche danger minimal morning quickly spike...   \n",
       "\n",
       "                                   problem_type_text  \\\n",
       "0  expect warmest temperature almost week enough ...   \n",
       "\n",
       "                            forecast_discussion_text  \\\n",
       "0  cornice fall snow blanket cornice rock face ne...   \n",
       "\n",
       "                                       combined_text tavg tmin  tmax prcp  \\\n",
       "0  avalanche danger minimal morning quickly spike...  7.6 -0.9  15.9  0.0   \n",
       "\n",
       "    wdir    pres tsun  \n",
       "0  225.3  1024.0  0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "all_zones_df = all_zones_df.head(1)\n",
    "all_zones_df = utils.add_weather_to_reports(all_zones_df)\n",
    "all_zones_df.head()\n",
    "utils.dataframe_to_postgres(all_zones_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an LSTM to predict the current avalanche danger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/snap/core20/current/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /lib/x86_64-linux-gnu/libproxy.so.1)\n",
      "Failed to load module: /home/jaymin/snap/code/common/.cache/gio-modules/libgiolibproxy.so\n",
      "libva error: vaGetDriverNameByIndex() failed with unknown libva error, driver_name = (null)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening in existing browser session.\n"
     ]
    }
   ],
   "source": [
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "p = figure(title=\"Avalanche Risk 22-23\", x_axis_label='Date', y_axis_label='Value')\n",
    "\n",
    "p.line(x='time', y='temp', legend_label=\"Temperature\", color='red', source=weather_and_risk_df)\n",
    "# p.line(x='time', y='dwpt', legend_label=\"Dew Point\", source=weather_and_risk_df)\n",
    "# p.line(x='time', y='rhum', legend_label=\"Relative Humidity\", source=weather_and_risk_df)\n",
    "# p.line(x='time', y='prcp', legend_label=\"Precipitation\", source=weather_and_risk_df)\n",
    "# p.line(x='time', y='wdir', legend_label=\"Wind Direction\", source=weather_and_risk_df)\n",
    "p.line(x='time', y='wspd', legend_label=\"Wind Speed\", source=weather_and_risk_df)\n",
    "# p.line(x='time', y='pres', legend_label=\"Pressure\", source=weather_and_risk_df)\n",
    "# p.line(x='time', y='coco', legend_label=\"Cloud Cover\", source=weather_and_risk_df)\n",
    "\n",
    "hover = HoverTool(tooltips=[(\"Avalanche Risk\", \"@risk\")], mode='vline')\n",
    "p.add_tools(hover)\n",
    "\n",
    "output_file(\"output_data/avalanche_risk_22-23.html\")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "8/8 [==============================] - 5s 11ms/step - loss: 2.1643\n",
      "Epoch 2/16\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.9405\n",
      "Epoch 3/16\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.7272\n",
      "Epoch 4/16\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.4953\n",
      "Epoch 5/16\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.2299\n",
      "Epoch 6/16\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9206\n",
      "Epoch 7/16\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6316\n",
      "Epoch 8/16\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6196\n",
      "Epoch 9/16\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6109\n",
      "Epoch 10/16\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5933\n",
      "Epoch 11/16\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6004\n",
      "Epoch 12/16\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6023\n",
      "Epoch 13/16\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5972\n",
      "Epoch 14/16\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5993\n",
      "Epoch 15/16\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5965\n",
      "Epoch 16/16\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5937\n",
      "Test MSE: 0.491\n"
     ]
    }
   ],
   "source": [
    "weather_and_risk_df['time'] = pd.to_datetime(weather_and_risk_df['time'])\n",
    "weather_and_risk_df['time'] = weather_and_risk_df['time'].apply(lambda x: x.timestamp())\n",
    "\n",
    "X = weather_and_risk_df.iloc[:, :-1].values\n",
    "y = weather_and_risk_df.iloc[:, -1].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "n_samples, n_time_steps = X.shape\n",
    "n_features = 1\n",
    "X = X.reshape((n_samples, n_time_steps, n_features))\n",
    "\n",
    "train_sie = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_sie], X[train_sie:]\n",
    "y_train, y_test = y[:train_sie], y[train_sie:]\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_time_steps, n_features)))\n",
    "model.add(Bidirectional(LSTM(25, activation='relu'), input_shape=(n_time_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=16, batch_size=16, verbose=1)\n",
    "\n",
    "mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test MSE: %.3f' % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temp</th>\n",
       "      <th>dwpt</th>\n",
       "      <th>rhum</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "      <th>coco</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>92.9</td>\n",
       "      <td>78.6</td>\n",
       "      <td>319.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>84.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1037.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>73.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1033.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-8.7</td>\n",
       "      <td>74.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>91.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>281.6</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1022.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>83.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>322.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1015.1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2023-04-13</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>78.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1015.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>75.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1013.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>2.2</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1018.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>78.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>90.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1015.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time  temp  dwpt  rhum  prcp   wdir  wspd    pres  coco  risk\n",
       "0    2022-11-04   2.6   1.6  92.9  78.6  319.2   6.9  1008.0  16.0    -1\n",
       "1    2022-11-16  -4.7  -7.0  84.8   0.0   74.7   8.0  1037.2   5.0    -1\n",
       "2    2022-11-18  -6.5 -10.6  73.2   0.0   88.5   9.0  1033.9   1.0    -1\n",
       "3    2022-11-21  -4.8  -8.7  74.2   0.0   66.4   6.4  1026.0   3.0    -1\n",
       "4    2022-11-23   1.1  -0.2  91.6   4.2  281.6   8.4  1022.1  16.0    -1\n",
       "..          ...   ...   ...   ...   ...    ...   ...     ...   ...   ...\n",
       "145  2023-04-12  -2.0  -4.4  83.8   0.5  322.2   4.0  1015.1  21.0     1\n",
       "146  2023-04-13  -1.1  -4.6  78.3   0.0  277.7   7.5  1015.2   5.0     1\n",
       "147  2023-04-14   0.6  -3.7  75.4   0.0  279.2   5.6  1013.3   5.0     0\n",
       "148  2023-04-15   2.2  -3.0  69.0   0.3   51.9   4.4  1018.2   7.0     1\n",
       "149  2023-04-16   0.7  -2.7  78.7   3.9   90.4   7.2  1015.2  15.0    -1\n",
       "\n",
       "[150 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_and_risk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting data from the database:\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(\"dbname='snowpackprediction' user='jaymin' host='localhost' password='password'\")\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "weather_df = pd.DataFrame(cursor.execute(\"SELECT * FROM weather_data\"))\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Score:  0.4\n"
     ]
    }
   ],
   "source": [
    "X = weather_and_risk_df[['temp', 'dwpt', 'rhum', 'prcp', 'wdir', 'wspd', 'pres', 'coco']] # Features\n",
    "y = weather_and_risk_df['risk'] # Labels\n",
    "\n",
    "# Making a decision tree with Sklearn:\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X[:-10], y[:-10])\n",
    "# fig = plt.figure(figsize=(25,20))\n",
    "# fig = tree.plot_tree(clf)\n",
    "clf.predict(X[-10:])\n",
    "print(\"Decision Tree Score: \", clf.score(X[-10:], y[-10:]))\n",
    "# conf_matrix = confusion_matrix(clf.predict(X), y)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(3, 3))\n",
    "# ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "# for i in range(conf_matrix.shape[0]):\n",
    "#     for j in range(conf_matrix.shape[1]):\n",
    "#         ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "# plt.xlabel('Predictions', fontsize=18)\n",
    "# plt.ylabel('Actuals', fontsize=18)\n",
    "# plt.title('Confusion Matrix', fontsize=18)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/data_collection.ipynb Cell 13\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m report_text \u001b[39m=\u001b[39m row\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# report = row.find_all('a')[0]['href']\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X14sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m report \u001b[39m=\u001b[39m Select(browser\u001b[39m.\u001b[39mfind_element(By\u001b[39m.\u001b[39mLINK_TEXT(report_text)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(report)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m date \u001b[39m=\u001b[39m row\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39mtd\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "# Scraping the avalanche data from the NWAC website:\n",
    "\n",
    "# Xpath: //*[@id=\"afp-forecast-widget\"]/div/div/div[1]/div[2]/div[1]/table/tbody/tr[1]/td[1]/div/a\n",
    "\n",
    "# Using Selenium to get the avalanche forecast data:\n",
    "date_risks = []\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "url = 'https://nwac.us/avalanche-forecast/#/archive'\n",
    "browser.get(url)\n",
    "# Finding by XPATH:\n",
    "select_element = Select(browser.find_element(By.XPATH,'//*[@id=\"afp-forecast-widget\"]/div/div/div[1]/div[1]/div/div[1]/div[2]/div[2]/select'))\n",
    "# Selecting Snoqualmie Pass from dropdown menu:\n",
    "select_element.select_by_visible_text(\"Snoqualmie Pass\")\n",
    "\n",
    "response = browser.page_source\n",
    "\n",
    "soup = bs.BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "prediction_table = soup.find_all('tr', {'class': 'VueTables__row'})\n",
    "for row in prediction_table:\n",
    "    report_text = row.find_all('a')[0].text\n",
    "    # report = row.find_all('a')[0]['href']\n",
    "    report = Select(browser.find_element(By.LINK_TEXT(report_text)))\n",
    "    print(report)\n",
    "    date = row.find_all('td')[0].text\n",
    "\n",
    "    org_date = datetime.strptime(date, '%b %d, %Y')\n",
    "    new_date = datetime.strftime(org_date, '%Y-%m-%d')\n",
    "    new_date = datetime.strptime(new_date, '%Y-%m-%d')\n",
    "    date_risks.append([new_date, row.find_all('td')[5].text])\n",
    "\n",
    "# Going to the next page:\n",
    "select_element = browser.find_element(By.XPATH,'//*[@id=\"afp-forecast-widget\"]/div/div/div[1]/div[2]/div[2]/nav/ul/li[4]/a')\n",
    "select_element.click()\n",
    "\n",
    "response = browser.page_source\n",
    "\n",
    "soup = bs.BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "prediction_table = soup.find_all('tr', {'class': 'VueTables__row'})\n",
    "for row in prediction_table:\n",
    "    date = row.find_all('td')[0].text\n",
    "    org_date = datetime.strptime(date, '%b %d, %Y')\n",
    "    new_date = datetime.strftime(org_date, '%Y-%m-%d')\n",
    "    new_date = datetime.strptime(new_date, '%Y-%m-%d')\n",
    "    date_risks.append([new_date, row.find_all('td')[5].text])\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "date_risks = pd.DataFrame(date_risks, columns=['time', 'risk'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snowpilot Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExpatError",
     "evalue": "syntax error: line 1, column 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExpatError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jaymin/Desktop/Spring 2023/CPSC325/SnowPackPrediction/data_collection.ipynb Cell 13\u001b[0m in \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39m\"\u001b[39m\u001b[39minput_data/snowpilot_data\u001b[39m\u001b[39m\"\u001b[39m): \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minput_data/snowpilot_data/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m filename\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     timestamp \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(utils\u001b[39m.\u001b[39msnowpilot_xml_to_dict(filename)[\u001b[39m'\u001b[39m\u001b[39m@timestamp\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     timestamp \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m# Converting from milliseconds\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jaymin/Desktop/Spring%202023/CPSC325/SnowPackPrediction/data_collection.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     date \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mfromtimestamp(timestamp)\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Spring 2023/CPSC325/SnowPackPrediction/utils.py:24\u001b[0m, in \u001b[0;36msnowpilot_xml_to_dict\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(fname, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m     22\u001b[0m     sp_xml \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread()\n\u001b[0;32m---> 24\u001b[0m sp_xml \u001b[39m=\u001b[39m xmltodict\u001b[39m.\u001b[39;49mparse(sp_xml)\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m sp_xml[\u001b[39m'\u001b[39m\u001b[39mPit_Observation\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xmltodict.py:378\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(xml_input, encoding, expat, process_namespaces, namespace_separator, disable_entities, process_comments, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m     parser\u001b[39m.\u001b[39mParse(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    377\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     parser\u001b[39m.\u001b[39;49mParse(xml_input, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    379\u001b[0m \u001b[39mreturn\u001b[39;00m handler\u001b[39m.\u001b[39mitem\n",
      "\u001b[0;31mExpatError\u001b[0m: syntax error: line 1, column 0"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "\n",
    "sp_data = []\n",
    "for filename in os.listdir(\"input_data/snowpilot_data\"): \n",
    "    filename = \"input_data/snowpilot_data/\" + filename\n",
    "    timestamp = int(utils.snowpilot_xml_to_dict(filename)['@timestamp'])\n",
    "    timestamp /= 1000 # Converting from milliseconds\n",
    "\n",
    "    date = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')\n",
    "\n",
    "    layers = utils.snowpilot_xml_to_dict(filename)['Layer']\n",
    "\n",
    "    layers_dict = {}\n",
    "\n",
    "    for layer in layers:\n",
    "        layers_dict[layer['@layerNumber']] = [layer['@startDepth'], layer['@endDepth'], layer['@hardness1']]\n",
    "\n",
    "    chart_df = pd.DataFrame.from_dict(layers_dict, orient='index', columns=['startDepth', 'endDepth', 'hardness1'])\n",
    "    sp_data.append((date, chart_df))\n",
    "sp_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas:\n",
    "\n",
    "- Really only need to predict the hardness of the snow layers. Graph can be made from everything else\n",
    "- Snow depth can be retrieved from the Snowpilot Data\n",
    "- Take basically all of the attributes possible from the weather data, use decision tree to find the most influential factors in determinding the layer hardness\n",
    "    - Will need to look at (some) historical data for the best results here\n",
    "- End results does not have to be the same format of the Snowpilot charts\n",
    "    - Could have the layers be color coded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
